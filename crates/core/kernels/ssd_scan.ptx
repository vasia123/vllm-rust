//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-32267302
// Cuda compilation tools, release 12.0, V12.0.140
// Based on NVVM 7.0.1
//

.version 8.0
.target sm_89
.address_size 64

	// .globl	ssd_scan_f32
.extern .shared .align 16 .b8 shmem[];

.visible .entry ssd_scan_f32(
	.param .u64 ssd_scan_f32_param_0,
	.param .u64 ssd_scan_f32_param_1,
	.param .u64 ssd_scan_f32_param_2,
	.param .u64 ssd_scan_f32_param_3,
	.param .u64 ssd_scan_f32_param_4,
	.param .u64 ssd_scan_f32_param_5,
	.param .u64 ssd_scan_f32_param_6,
	.param .u64 ssd_scan_f32_param_7,
	.param .u32 ssd_scan_f32_param_8,
	.param .u32 ssd_scan_f32_param_9,
	.param .u32 ssd_scan_f32_param_10,
	.param .u32 ssd_scan_f32_param_11,
	.param .u32 ssd_scan_f32_param_12,
	.param .u32 ssd_scan_f32_param_13,
	.param .u32 ssd_scan_f32_param_14
)
{
	.local .align 16 .b8 	__local_depot0[1024];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<21>;
	.reg .f32 	%f<88>;
	.reg .b32 	%r<97>;
	.reg .b64 	%rd<69>;


	mov.u64 	%SPL, __local_depot0;
	ld.param.u64 	%rd27, [ssd_scan_f32_param_0];
	ld.param.u64 	%rd23, [ssd_scan_f32_param_1];
	ld.param.u64 	%rd24, [ssd_scan_f32_param_2];
	ld.param.u64 	%rd28, [ssd_scan_f32_param_3];
	ld.param.u64 	%rd25, [ssd_scan_f32_param_4];
	ld.param.u64 	%rd26, [ssd_scan_f32_param_5];
	ld.param.u64 	%rd29, [ssd_scan_f32_param_6];
	ld.param.u64 	%rd30, [ssd_scan_f32_param_7];
	ld.param.s32 	%rd4, [ssd_scan_f32_param_8];
	ld.param.u32 	%r43, [ssd_scan_f32_param_9];
	ld.param.u32 	%r44, [ssd_scan_f32_param_10];
	ld.param.u32 	%r45, [ssd_scan_f32_param_11];
	ld.param.u32 	%r46, [ssd_scan_f32_param_12];
	ld.param.u32 	%r47, [ssd_scan_f32_param_13];
	ld.param.u32 	%r48, [ssd_scan_f32_param_14];
	cvta.to.global.u64 	%rd1, %rd30;
	cvta.to.global.u64 	%rd2, %rd27;
	add.u64 	%rd3, %SPL, 0;
	mov.u32 	%r1, %ctaid.x;
	div.u32 	%r3, %r1, %r44;
	mul.lo.s32 	%r49, %r3, %r44;
	sub.s32 	%r2, %r1, %r49;
	cvta.to.global.u64 	%rd32, %rd28;
	mul.wide.s32 	%rd33, %r2, 4;
	add.s64 	%rd34, %rd32, %rd33;
	ld.global.nc.f32 	%f1, [%rd34];
	cvta.to.global.u64 	%rd35, %rd29;
	add.s64 	%rd36, %rd35, %rd33;
	ld.global.nc.f32 	%f2, [%rd36];
	mad.lo.s32 	%r50, %r3, %r44, %r2;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r51, %r50, %r45, %r4;
	mul.lo.s32 	%r5, %r51, %r47;
	setp.lt.s32 	%p1, %r47, 1;
	@%p1 bra 	$L__BB0_7;

	add.s32 	%r53, %r47, -1;
	and.b32  	%r87, %r47, 3;
	setp.lt.u32 	%p2, %r53, 3;
	mov.u32 	%r86, 0;
	@%p2 bra 	$L__BB0_4;

	sub.s32 	%r85, %r47, %r87;

$L__BB0_3:
	add.s32 	%r55, %r86, %r5;
	mul.wide.s32 	%rd37, %r55, 4;
	add.s64 	%rd38, %rd1, %rd37;
	mul.wide.s32 	%rd39, %r86, 4;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.nc.f32 	%f15, [%rd38+12];
	ld.global.nc.f32 	%f16, [%rd38+8];
	ld.global.nc.f32 	%f17, [%rd38+4];
	ld.global.nc.f32 	%f18, [%rd38];
	st.local.v4.f32 	[%rd40], {%f18, %f17, %f16, %f15};
	add.s32 	%r86, %r86, 4;
	add.s32 	%r85, %r85, -4;
	setp.ne.s32 	%p3, %r85, 0;
	@%p3 bra 	$L__BB0_3;

$L__BB0_4:
	setp.eq.s32 	%p4, %r87, 0;
	@%p4 bra 	$L__BB0_7;

	mul.wide.s32 	%rd41, %r86, 4;
	add.s64 	%rd66, %rd3, %rd41;
	mad.lo.s32 	%r56, %r1, %r45, %r4;
	mad.lo.s32 	%r57, %r47, %r56, %r86;
	mul.wide.s32 	%rd42, %r57, 4;
	add.s64 	%rd65, %rd1, %rd42;

$L__BB0_6:
	.pragma "nounroll";
	ld.global.nc.f32 	%f19, [%rd65];
	st.local.f32 	[%rd66], %f19;
	add.s64 	%rd66, %rd66, 4;
	add.s64 	%rd65, %rd65, 4;
	add.s32 	%r87, %r87, -1;
	setp.ne.s32 	%p5, %r87, 0;
	@%p5 bra 	$L__BB0_6;

$L__BB0_7:
	setp.lt.s32 	%p6, %r43, 1;
	@%p6 bra 	$L__BB0_21;

	mul.lo.s32 	%r15, %r3, %r43;
	mov.u32 	%r16, %ntid.x;
	add.s32 	%r17, %r47, -1;
	and.b32  	%r18, %r47, 3;
	sub.s32 	%r19, %r47, %r18;
	cvta.to.global.u64 	%rd11, %rd26;
	cvta.to.global.u64 	%rd12, %rd25;
	cvta.to.global.u64 	%rd13, %rd23;
	cvta.to.global.u64 	%rd14, %rd24;
	div.s32 	%r20, %r2, %r48;
	mov.u32 	%r88, 0;

$L__BB0_9:
	add.s32 	%r22, %r88, %r15;
	setp.ge.s32 	%p7, %r4, %r47;
	@%p7 bra 	$L__BB0_12;

	mad.lo.s32 	%r59, %r22, %r46, %r20;
	mul.lo.s32 	%r23, %r59, %r47;
	mov.u32 	%r89, %r4;

$L__BB0_11:
	add.s32 	%r60, %r89, %r23;
	mul.wide.s32 	%rd43, %r60, 4;
	add.s64 	%rd44, %rd12, %rd43;
	ld.global.nc.f32 	%f20, [%rd44];
	shl.b32 	%r61, %r89, 2;
	mov.u32 	%r62, shmem;
	add.s32 	%r63, %r62, %r61;
	st.shared.f32 	[%r63], %f20;
	add.s64 	%rd45, %rd11, %rd43;
	ld.global.nc.f32 	%f21, [%rd45];
	shl.b32 	%r64, %r47, 2;
	add.s32 	%r65, %r63, %r64;
	st.shared.f32 	[%r65], %f21;
	add.s32 	%r89, %r89, %r16;
	setp.lt.s32 	%p8, %r89, %r47;
	@%p8 bra 	$L__BB0_11;

$L__BB0_12:
	bar.sync 	0;
	mad.lo.s32 	%r66, %r22, %r44, %r2;
	mul.wide.s32 	%rd46, %r66, 4;
	add.s64 	%rd47, %rd14, %rd46;
	ld.global.nc.f32 	%f3, [%rd47];
	mul.ftz.f32 	%f23, %f1, %f3;
	mul.ftz.f32 	%f24, %f23, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f4, %f24;
	mad.lo.s32 	%r67, %r66, %r45, %r4;
	cvt.s64.s32 	%rd15, %r67;
	mul.wide.s32 	%rd48, %r67, 4;
	add.s64 	%rd49, %rd13, %rd48;
	ld.global.nc.f32 	%f5, [%rd49];
	mov.f32 	%f87, 0f00000000;
	@%p1 bra 	$L__BB0_20;

	setp.lt.u32 	%p10, %r17, 3;
	mul.ftz.f32 	%f6, %f3, %f5;
	mov.f32 	%f87, 0f00000000;
	mov.u32 	%r92, 0;
	@%p10 bra 	$L__BB0_16;

	mov.u32 	%r91, %r19;

$L__BB0_15:
	mul.wide.s32 	%rd50, %r92, 4;
	add.s64 	%rd51, %rd3, %rd50;
	ld.local.v4.f32 	{%f28, %f29, %f30, %f31}, [%rd51];
	shl.b32 	%r70, %r92, 2;
	mov.u32 	%r71, shmem;
	add.s32 	%r72, %r71, %r70;
	ld.shared.v4.f32 	{%f36, %f37, %f38, %f39}, [%r72];
	mul.ftz.f32 	%f44, %f6, %f36;
	shl.b32 	%r73, %r47, 2;
	add.s32 	%r74, %r72, %r73;
	ld.shared.f32 	%f45, [%r74];
	fma.rn.ftz.f32 	%f46, %f4, %f28, %f44;
	fma.rn.ftz.f32 	%f47, %f46, %f45, %f87;
	mul.ftz.f32 	%f48, %f6, %f37;
	ld.shared.f32 	%f49, [%r74+4];
	fma.rn.ftz.f32 	%f50, %f4, %f29, %f48;
	fma.rn.ftz.f32 	%f51, %f50, %f49, %f47;
	mul.ftz.f32 	%f52, %f6, %f38;
	ld.shared.f32 	%f53, [%r74+8];
	fma.rn.ftz.f32 	%f54, %f4, %f30, %f52;
	fma.rn.ftz.f32 	%f55, %f54, %f53, %f51;
	mul.ftz.f32 	%f56, %f6, %f39;
	fma.rn.ftz.f32 	%f57, %f4, %f31, %f56;
	st.local.v4.f32 	[%rd51], {%f46, %f50, %f54, %f57};
	ld.shared.f32 	%f58, [%r74+12];
	fma.rn.ftz.f32 	%f87, %f57, %f58, %f55;
	add.s32 	%r92, %r92, 4;
	add.s32 	%r91, %r91, -4;
	setp.ne.s32 	%p11, %r91, 0;
	@%p11 bra 	$L__BB0_15;

$L__BB0_16:
	setp.eq.s32 	%p12, %r18, 0;
	@%p12 bra 	$L__BB0_20;

	setp.eq.s32 	%p13, %r18, 1;
	mul.wide.s32 	%rd52, %r92, 4;
	add.s64 	%rd16, %rd3, %rd52;
	ld.local.f32 	%f59, [%rd16];
	shl.b32 	%r75, %r92, 2;
	mov.u32 	%r76, shmem;
	add.s32 	%r31, %r76, %r75;
	ld.shared.f32 	%f60, [%r31];
	mul.ftz.f32 	%f61, %f6, %f60;
	fma.rn.ftz.f32 	%f62, %f4, %f59, %f61;
	st.local.f32 	[%rd16], %f62;
	shl.b32 	%r77, %r47, 2;
	add.s32 	%r32, %r31, %r77;
	ld.shared.f32 	%f63, [%r32];
	fma.rn.ftz.f32 	%f87, %f62, %f63, %f87;
	@%p13 bra 	$L__BB0_20;

	setp.eq.s32 	%p14, %r18, 2;
	ld.local.f32 	%f64, [%rd16+4];
	ld.shared.f32 	%f65, [%r31+4];
	mul.ftz.f32 	%f66, %f6, %f65;
	fma.rn.ftz.f32 	%f67, %f4, %f64, %f66;
	st.local.f32 	[%rd16+4], %f67;
	ld.shared.f32 	%f68, [%r32+4];
	fma.rn.ftz.f32 	%f87, %f67, %f68, %f87;
	@%p14 bra 	$L__BB0_20;

	ld.local.f32 	%f69, [%rd16+8];
	ld.shared.f32 	%f70, [%r31+8];
	mul.ftz.f32 	%f71, %f6, %f70;
	fma.rn.ftz.f32 	%f72, %f4, %f69, %f71;
	st.local.f32 	[%rd16+8], %f72;
	ld.shared.f32 	%f73, [%r32+8];
	fma.rn.ftz.f32 	%f87, %f72, %f73, %f87;

$L__BB0_20:
	fma.rn.ftz.f32 	%f74, %f2, %f5, %f87;
	shl.b64 	%rd53, %rd15, 2;
	add.s64 	%rd54, %rd2, %rd53;
	st.global.f32 	[%rd54], %f74;
	bar.sync 	0;
	add.s32 	%r88, %r88, 1;
	setp.lt.s32 	%p15, %r88, %r43;
	@%p15 bra 	$L__BB0_9;

$L__BB0_21:
	@%p1 bra 	$L__BB0_28;

	add.s32 	%r79, %r47, -1;
	and.b32  	%r96, %r47, 3;
	setp.lt.u32 	%p17, %r79, 3;
	mov.u32 	%r95, 0;
	@%p17 bra 	$L__BB0_25;

	sub.s32 	%r94, %r47, %r96;

$L__BB0_24:
	mul.wide.s32 	%rd55, %r95, 4;
	add.s64 	%rd56, %rd3, %rd55;
	ld.local.v4.f32 	{%f75, %f76, %f77, %f78}, [%rd56];
	add.s32 	%r81, %r95, %r5;
	cvt.s64.s32 	%rd57, %r81;
	add.s64 	%rd58, %rd57, %rd4;
	shl.b64 	%rd59, %rd58, 2;
	add.s64 	%rd60, %rd2, %rd59;
	st.global.f32 	[%rd60], %f75;
	st.global.f32 	[%rd60+4], %f76;
	st.global.f32 	[%rd60+8], %f77;
	st.global.f32 	[%rd60+12], %f78;
	add.s32 	%r95, %r95, 4;
	add.s32 	%r94, %r94, -4;
	setp.ne.s32 	%p18, %r94, 0;
	@%p18 bra 	$L__BB0_24;

$L__BB0_25:
	setp.eq.s32 	%p19, %r96, 0;
	@%p19 bra 	$L__BB0_28;

	mad.lo.s32 	%r82, %r1, %r45, %r4;
	mad.lo.s32 	%r83, %r47, %r82, %r95;
	cvt.s64.s32 	%rd61, %r83;
	add.s64 	%rd62, %rd4, %rd61;
	shl.b64 	%rd63, %rd62, 2;
	add.s64 	%rd68, %rd2, %rd63;
	mul.wide.s32 	%rd64, %r95, 4;
	add.s64 	%rd67, %rd3, %rd64;

$L__BB0_27:
	.pragma "nounroll";
	ld.local.f32 	%f83, [%rd67];
	st.global.f32 	[%rd68], %f83;
	add.s64 	%rd68, %rd68, 4;
	add.s64 	%rd67, %rd67, 4;
	add.s32 	%r96, %r96, -1;
	setp.ne.s32 	%p20, %r96, 0;
	@%p20 bra 	$L__BB0_27;

$L__BB0_28:
	ret;

}

